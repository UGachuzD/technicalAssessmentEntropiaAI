{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06bedd5e",
   "metadata": {},
   "source": [
    "# EntropiaAI | Technical Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0826d404",
   "metadata": {},
   "source": [
    "## Phase 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b8e3732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.4\n",
      "uv 0.10.2 (a788db7e5 2026-02-10)\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!uv --version\n",
    "#!uv pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32deb07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: True\n",
      "Model: gemini-2.5-flash-lite\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "load_dotenv(Path.cwd() / \".env\", override=True)\n",
    "\n",
    "print(\"API Key loaded:\", bool(os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GOOGLE_API_KEY\")))\n",
    "print(\"Model:\", os.getenv(\"GEMINI_MODEL\", \"gemini-2.0-flash\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c56fbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.llm import getChatModel\n",
    "from src.router import decideFile\n",
    "from src.retriever import retrieveAndAnswer\n",
    "from src.stylist import styleAnswer, StyledAnswers\n",
    "from src.workflow import questionAgent\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df52b5c",
   "metadata": {},
   "source": [
    "## Phase 2. The Core Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e72011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "llm = getChatModel()\n",
    "demo_messages = [\n",
    "    SystemMessage(content=\"Eres un asistente. Responde solo: OK.\"),\n",
    "    HumanMessage(content=\"Hola\")\n",
    "]\n",
    "resp = llm.invoke(demo_messages)\n",
    "print(\"Response:\", resp.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98989fb2",
   "metadata": {},
   "source": [
    "## Phase 3. The Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Router\n",
    "\n",
    "tests_router = [\n",
    "    \"¿Qué dice el cookbook sobre el uso de etiquetas XML para GPT-4.1?\",\n",
    "    \"¿Top 5 estados más calientes en agosto de 2021?\",\n",
    "    \"¿Cuántas razas de maíz son nativas en México?\",\n",
    "    \"¿Cuál es el clima en Marte?\" \n",
    "]\n",
    "\n",
    "for t in tests_router:\n",
    "    d = decideFile(llm, t)\n",
    "    print(f\"Q: {t}\\n -> file: {d.filename} | reason: {d.reason}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78259804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "\n",
    "q = \"¿Cuáles fueron las 3 temperaturas mínimas en enero de 2020 en Mexico?\"\n",
    "decision = decideFile(llm, q)\n",
    "print(\"Selected:\", decision.filename)\n",
    "\n",
    "original_answer = retrieveAndAnswer(llm, decision.filename, q)\n",
    "print(original_answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylist\n",
    "\n",
    "styled = styleAnswer(llm, original_answer)\n",
    "\n",
    "print(\"Output\")\n",
    "print(json.dumps(styled, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdf9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow\n",
    "\n",
    "q = \"¿Top 5 estados más calientes en agosto de 2021?\"\n",
    "out = questionAgent(q, model_name=\"gemini-2.5-flash-lite\", include_trace=True)\n",
    "\n",
    "print(json.dumps(out, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d719406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workflow (Imagen)\n",
    "\n",
    "q = \"¿Cuántas razas de maíz son nativas en México?\"\n",
    "out = questionAgent(q, model_name=\"gemini-2.5-flash-lite\", include_trace=True)\n",
    "\n",
    "print(json.dumps(out, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253af145",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5c674a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST 1: ¿Algún consejo para promptear a GPT-5?\n",
      "Selected file: GPT-41_PromptingGuide.txt\n",
      "Router reason: La pregunta busca consejos para promptear a un modelo GPT. Aunque menciona GPT-5, la guía de prompting para GPT-4.1 es el recurso más relevante y cercano disponible para ofrecer consejos sobre cómo interactuar con modelos de lenguaje de la serie GPT.\n",
      "\n",
      "Original answer:\n",
      " No tengo información suficiente en el archivo proporcionado.\n",
      "\n",
      "Dry answer:\n",
      " Información insuficiente en el archivo.\n",
      "\n",
      "Funny answer:\n",
      " Mi sistema está buscando, pero este archivo está más vacío que mi nevera un lunes por la mañana. ¡No hay información suficiente!\n",
      "\n",
      "TEST 2: ¿Por qué el huitlacoche es superior en nutrientes al maíz tradicional?\n",
      "Selected file: maiz_info.jpg\n",
      "Router reason: La pregunta es sobre el maíz y el huitlacoche. El archivo 'maiz_info.jpg' es una imagen que podría contener información relevante sobre el maíz, incluyendo comparaciones nutricionales o datos sobre el huitlacoche.\n",
      "\n",
      "Original answer:\n",
      " No tengo información suficiente en la imagen.\n",
      "\n",
      "Dry answer:\n",
      " Información insuficiente en la imagen.\n",
      "\n",
      "Funny answer:\n",
      " ¡Vaya! Parece que la imagen me dejó con la mente en blanco, no encuentro datos suficientes.\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    # \"¿Qué dice el cookbook sobre el uso de etiquetas XML para GPT-4.1?\",\n",
    "    \"¿Algún consejo para promptear a GPT-5?\",\n",
    "    # \"¿Top 5 estados más calientes en agosto de 2021?\",\n",
    "    # \"¿Cuáles fueron las 3 temperaturas mínimas en diciembre de 2025? ¿En dónde?\",\n",
    "    # \"¿Cuántas razas de maíz son nativas en México?\",\n",
    "    \"¿Por qué el huitlacoche es superior en nutrientes al maíz tradicional?\",\n",
    "]\n",
    "\n",
    "for i, q in enumerate(tests, 1):\n",
    "    print(f\"\\nTEST {i}: {q}\")\n",
    "\n",
    "    out = questionAgent(q, model_name=\"gemini-2.5-flash\", include_trace=True)\n",
    "\n",
    "    trace = out.get(\"_trace\", {})\n",
    "    print(\"Selected file:\", trace.get(\"selected_file\"))\n",
    "    print(\"Router reason:\", trace.get(\"router_reason\"))\n",
    "\n",
    "    print(\"\\nOriginal answer:\\n\", out.get(\"original_answer\"))\n",
    "    print(\"\\nDry answer:\\n\", out.get(\"dry_answer\"))\n",
    "    print(\"\\nFunny answer:\\n\", out.get(\"funny_answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206cc1ca",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "### *Tokens & Cost* <br>\n",
    "Por cada pregunta que se le hacia al agente, se consumian 3 llamadas al modelo (1 para elegir el archivo, 1 para responder con contexto y 1 para reescribir en JSON con los 3 tonos) \n",
    "\n",
    "Lo optimizaria, en un caso real solo añadir el estilo en caso de que sea requisito porque no aporta valor a la informacion, esencialmente es la misma pero de otra forma. Y para el caso de las imagenes, tal vez usar OCR (unicamente si se que las imagenes conservan mas texto y no se requiere encontrarle sentido a lo que se ve) y ese texto mejor pasarlo al modelo ya que por lo general son mas costosas las llamadas teniendo como entrada imagenes que texto.\n",
    "\n",
    "### *Latency* <br>\n",
    "Considero que las respuestas que da son un tiempo aceptable ya que por pregunta, se tardo alrededor de 8-9 segundos ya dando las 3 formas de estilo.\n",
    "\n",
    "### *Evaluation* <br>\n",
    "Automatizar pruebas (Con el costo que eso implica por las llamadas) para contar casos correctos de asignacion de archivo, de saber cuando el contexto no contiene la info y para preguntas con el CSV realizar ejemplos usando pandas. \n",
    "\n",
    "### *Escalability* <br>\n",
    "Para tener unicamente 3 archivos de los cuales elegir funciona, pero escalar a mas tipos de archivos o diferentes archivos con la misma extension representa un problema para el LLM recordar este catalogo.\n",
    "\n",
    "### *Autonomy* <br>\n",
    "Ventajas: la rapidez en el desarrollo conservando el desempeño pero mayores costos\n",
    "Contras: por lo regular suele ser mas barato y personalizable codificar, pero con la curva de aprendizaje que esto implica\n",
    "\n",
    "### *Personal Retrospective* <br>\n",
    "La evaluacion fue demasiado completa por abarcar las etapas que considero fundamentales en un sistema de preguntas y respuestas, con su nivel de complejidad para poder resolver algunos aspectos que no estaban muy frescos o en completo desconocimiento pero para la prueba el investigar e ingeniar la forma de resolverlo me parecio interesante. \n",
    "Si me veo en un futuro creando soluciones de este tipo por mi gusto e interes por aprender y especializarme en temas relacionados con la inteligencia artificial. Siento que un contexto tan cercado a la realidad obtenido en esta prueba refuerza mi decision de seguir por este camino y los retos que esto implique. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "technicalAssessmentEntropiaAI (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
